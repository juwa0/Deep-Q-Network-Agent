# Deep Q-Network (DQN) Agent â€” CarRacing-v3 ðŸš—ðŸ’¨

Re-implementation of **â€œPlaying Atari with Deep Reinforcement Learningâ€**
(Mnih et al., 2015), applied to the **Gymnasium `CarRacing-v3`** environment (discrete action wrapper).



## ðŸ”§ Quick start

```bash
# 1) create / activate an env (optional)
conda create -n carla_dqn python=3.10 -y
conda activate carla_dqn

# 2) install deps
pip install torch \
            gymnasium[box2d] \
            opencv-python-headless \
            matplotlib numpy

# 3) train
python train_dqn.py
# â‡’ dqn_carracing.pth  (weights)
# â‡’ reward_plot.png    (learning curve)
```

## ðŸ“ Hyper-parameters (paper defaults)

| Parameter           | Value                      |
| ------------------- | -------------------------- |
| stacked frames      | **4**                      |
| replay buffer size  | 100 000                    |
| batch size          | 32                         |
| discount Î³          | 0.99                       |
| optimizer           | RMSprop (lr 1e-4)          |
| Îµ-greedy schedule   | 1.0 â†’ 0.1 over 100 k steps |
| target-net sync     | every 1 000 steps          |
| episodes (this run) | 500                        |

---

## ðŸ“ˆ Result

![Reward curve](reward_plot.png)
The agent quickly learns to stay on track and accumulates positive reward; performance keeps improving with longer training (try 1â€“2 M frames).


## ðŸ“œ Paper citation

> **Mnih, V.** *et al.* â€œPlaying Atari with Deep Reinforcement Learning.â€
> arXiv:1312.5602 (2013).

---

## ðŸ“„ License

MIT Â© 2025 **juwa0** â€” free to use, modify, and share.
